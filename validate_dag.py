#!/usr/bin/env python3
"""
Pre-deployment DAG validation script
Run this before CDK deployment to catch DAG issues early
"""

import sys
import os
import ast
from pathlib import Path

def validate_syntax():
    """Validate Python syntax for DAG files"""
    print("ğŸ” Validating DAG syntax...")
    
    dag_files = [
        "assets/mwaa_dags/dags/scripts/mwaa_blogpost_data_pipeline.py",
        "assets/mwaa_dags/dags/custom/glue_trigger_crawler_operator.py"
    ]
    
    for file_path in dag_files:
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r') as f:
                    ast.parse(f.read())
                print(f"  âœ… {os.path.basename(file_path)}")
            except SyntaxError as e:
                print(f"  âŒ Syntax error in {file_path}: {e}")
                return False
        else:
            print(f"  âš ï¸  File not found: {file_path}")
            return False
    
    return True

def validate_imports():
    """Test that DAG imports work correctly"""
    print("ğŸ“¥ Validating DAG imports...")
    
    # Add DAGs directory to path
    dags_path = os.path.join(os.getcwd(), "assets", "mwaa_dags", "dags")
    if dags_path not in sys.path:
        sys.path.insert(0, dags_path)
    
    try:
        # Mock Airflow Variables to avoid dependency issues
        import unittest.mock
        with unittest.mock.patch('airflow.models.Variable.get', return_value='test-value'):
            # Test custom operator
            from custom.glue_trigger_crawler_operator import GlueTriggerCrawlerOperator
            print("  âœ… Custom Glue operator")
            
            # Test main DAG
            from scripts.mwaa_blogpost_data_pipeline import dag
            print("  âœ… Main DAG")
            
            # Basic validation
            if dag.dag_id != 'mwaa_blogpost_data_pipeline':
                print(f"  âŒ Unexpected DAG ID: {dag.dag_id}")
                return False
            
            if len(dag.tasks) == 0:
                print("  âŒ No tasks found in DAG")
                return False
            
            print(f"  âœ… DAG structure (found {len(dag.tasks)} tasks)")
            
        return True
    except Exception as e:
        print(f"  âŒ Import failed: {e}")
        return False

def validate_requirements():
    """Check that requirements.txt includes necessary dependencies"""
    print("ğŸ“¦ Validating requirements...")
    
    req_file = "requirements.txt"
    if not os.path.exists(req_file):
        print(f"  âŒ {req_file} not found")
        return False
    
    with open(req_file, 'r') as f:
        requirements = f.read().lower()
    
    required_packages = [
        'apache-airflow-providers-amazon',
        'boto3'
    ]
    
    for package in required_packages:
        if package not in requirements:
            print(f"  âŒ Missing required package: {package}")
            return False
        else:
            print(f"  âœ… {package}")
    
    return True

def main():
    """Main validation function"""
    print("ğŸš€ Pre-deployment DAG Validation")
    print("=" * 40)
    
    # Change to project directory
    script_dir = Path(__file__).parent
    os.chdir(script_dir)
    
    all_passed = True
    
    # Run validations
    if not validate_syntax():
        all_passed = False
    
    if not validate_imports():
        all_passed = False
    
    if not validate_requirements():
        all_passed = False
    
    print("=" * 40)
    if all_passed:
        print("âœ… All validations passed! Ready for deployment.")
        return 0
    else:
        print("âŒ Validation failed! Please fix issues before deployment.")
        return 1

if __name__ == "__main__":
    sys.exit(main())
